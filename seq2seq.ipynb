{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import BABI20\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.nn.init as I\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import re\n",
    "from functools import reduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(batch_size, memory_size, task, joint, tenK):\n",
    "    train_iter, valid_iter, test_iter = BABI20.iters(\n",
    "        batch_size=batch_size, memory_size=memory_size, task=task, joint=joint, tenK=tenK, device=torch.device(\"cpu\"),\n",
    "    shuffle=True)\n",
    "    return train_iter, valid_iter, test_iter, train_iter.dataset.fields['query'].vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter, vocab = dataloader(64, 50, 6, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split(r'(\\W+)', sent) if x.strip()]\n",
    "\n",
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        #line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            # reset story when line ID=1 (start of new story)\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            # this line is tab separated Q, A &amp;amp;amp;amp;amp; support fact ID\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            # tokenize the words of question\n",
    "            q = tokenize(q)\n",
    "            a = tokenize(a)\n",
    "            # Provide all the sub-stories till this question\n",
    "            substory = [x for x in story if x]\n",
    "            # A story ends and is appended to global story data-set\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            # this line is a sentence of story\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "def get_stories(f):\n",
    "    # read the data file and parse 10k stories\n",
    "    data = parse_stories(f.readlines())\n",
    "    # lambda func to flatten the list of sentences into one list\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    # creating list of tuples for each story\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data]\n",
    "    #data = [((story), q, answer) for story, q, answer in data]\n",
    "    return data\n",
    "\n",
    "with open('./tasks/task_1.txt') as f:\n",
    "    all_stories = get_stories(f)\n",
    "    \n",
    "# train_stories, test_stories = train_test_split(all_stories, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_question_story(data):\n",
    "    merged_data = [(s+['SOQ']+q, a) for s,q,a in data]\n",
    "    return merged_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def readLangs(all_stories):\n",
    "    print(\"Reading data...\")\n",
    "\n",
    "    pairs = merge_question_story(all_stories)\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    lang = Lang()\n",
    "    return lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(all_stories):\n",
    "    lang, pairs = readLangs(all_stories)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        lang.addSentence(pair[0])\n",
    "        lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(lang.n_words)\n",
    "    return lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Read 5000 sentence pairs\n",
      "Counted words:\n",
      "23\n",
      "(['Mary', 'went', 'to', 'the', 'garden', '.', 'Mary', 'went', 'to', 'the', 'bedroom', '.', 'Mary', 'moved', 'to', 'the', 'office', '.', 'Sandra', 'went', 'to', 'the', 'kitchen', '.', 'Mary', 'moved', 'to', 'the', 'hallway', '.', 'John', 'journeyed', 'to', 'the', 'bathroom', '.', 'SOQ', 'Where', 'is', 'Mary', '?'], ['hallway'])\n"
     ]
    }
   ],
   "source": [
    "lang, pairs = prepareData(all_stories)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(lang, pair):\n",
    "    input_tensor = tensorFromSentence(lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embed_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size  = embed_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, embed_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-d53e66124516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-d53e66124516>\u001b[0m in \u001b[0;36mAttnDecoderRNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "#         self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "#         attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "       \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        input_length = source.size(0) #get the input length (number of words in sentence)\n",
    "        batch_size = target.shape[1] \n",
    "        target_length = target.shape[0]\n",
    "        vocab_size = self.decoder.output_size\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(source[i], self.encoder.initHidden())\n",
    "\n",
    "        decoder_hidden = encoder_hidden.to(device)\n",
    "  \n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
    "\n",
    "        for t in range(target_length):   \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = (target[t] if teacher_force else topi)\n",
    "            if(teacher_force == False and input.item() == EOS_token):\n",
    "                break\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def clacModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "\n",
    "#calculate the loss from a predicted sentence with the expected result\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "def trainModel(model, lang, pairs, num_iteration=20000):\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "    training_pairs = [tensorsFromPair(lang, random.choice(pairs))\n",
    "                     for i in range(num_iteration)]\n",
    "    print(training_pairs[0])\n",
    "  \n",
    "    for itera in range(1, num_iteration+1):\n",
    "        training_pair = training_pairs[itera - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = clacModel(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if itera % 100 == 0:\n",
    "            avarage_loss= total_loss_iterations / 100\n",
    "            total_loss_iterations = 0\n",
    "            print(f\"Iter: {itera}, loss: {avarage_loss}\")\n",
    "          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(23, 12)\n",
      "  (gru): GRU(12, 12)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embedding): Embedding(23, 12)\n",
      "  (gru): GRU(12, 12)\n",
      "  (out): Linear(in_features=12, out_features=23, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "(tensor([[14],\n",
      "        [21],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [20],\n",
      "        [ 7],\n",
      "        [19],\n",
      "        [21],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [ 2],\n",
      "        [21],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [18],\n",
      "        [ 7],\n",
      "        [13],\n",
      "        [17],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [13],\n",
      "        [21],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [20],\n",
      "        [ 7],\n",
      "        [ 2],\n",
      "        [17],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [19],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [20],\n",
      "        [ 7],\n",
      "        [13],\n",
      "        [21],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [16],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [ 2],\n",
      "        [12],\n",
      "        [ 1]], device='cuda:0'), tensor([[8],\n",
      "        [1]], device='cuda:0'))\n",
      "Iter: 100, loss: 2.1584483909606935\n",
      "Iter: 200, loss: 1.7867854869365691\n",
      "Iter: 300, loss: 1.6343533182144165\n",
      "Iter: 400, loss: 1.5348074734210968\n",
      "Iter: 500, loss: 1.4561782813072204\n",
      "Iter: 600, loss: 1.3701473248004914\n",
      "Iter: 700, loss: 1.3150172686576844\n",
      "Iter: 800, loss: 1.2754808914661409\n",
      "Iter: 900, loss: 1.213244652748108\n",
      "Iter: 1000, loss: 1.1708611142635346\n",
      "Iter: 1100, loss: 1.1398459804058074\n",
      "Iter: 1200, loss: 1.0843193185329438\n",
      "Iter: 1300, loss: 1.0331801056861878\n",
      "Iter: 1400, loss: 1.0021376931667327\n",
      "Iter: 1500, loss: 0.9821104657649994\n",
      "Iter: 1600, loss: 0.979196834564209\n",
      "Iter: 1700, loss: 0.9702057027816773\n",
      "Iter: 1800, loss: 0.956780002117157\n",
      "Iter: 1900, loss: 0.9485513806343079\n",
      "Iter: 2000, loss: 0.94850745677948\n",
      "Iter: 2100, loss: 0.9359334123134613\n",
      "Iter: 2200, loss: 0.9383593511581421\n",
      "Iter: 2300, loss: 0.9430160415172577\n",
      "Iter: 2400, loss: 0.929413093328476\n",
      "Iter: 2500, loss: 0.9352268052101135\n",
      "Iter: 2600, loss: 0.9254874753952026\n",
      "Iter: 2700, loss: 0.9263089799880981\n",
      "Iter: 2800, loss: 0.9349782800674439\n",
      "Iter: 2900, loss: 0.9282434129714966\n",
      "Iter: 3000, loss: 0.9311919915676117\n",
      "Iter: 3100, loss: 0.9203746795654297\n",
      "Iter: 3200, loss: 0.9297330319881439\n",
      "Iter: 3300, loss: 0.9263923025131225\n",
      "Iter: 3400, loss: 0.9119014501571655\n",
      "Iter: 3500, loss: 0.9141584587097168\n",
      "Iter: 3600, loss: 0.9285691332817078\n",
      "Iter: 3700, loss: 0.920370717048645\n",
      "Iter: 3800, loss: 0.9217403650283813\n",
      "Iter: 3900, loss: 0.9142561423778534\n",
      "Iter: 4000, loss: 0.9273876285552979\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_size = 12\n",
    "hidden_size = 12\n",
    "num_layers = 1\n",
    "num_iteration = 4000\n",
    "input_size = lang.n_words\n",
    "output_size = lang.n_words\n",
    "\n",
    "#create encoder-decoder model\n",
    "encoder = EncoderRNN(input_size, hidden_size, embed_size)\n",
    "decoder = DecoderRNN(output_size, hidden_size, embed_size)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "#print model \n",
    "print(encoder)\n",
    "print(decoder)\n",
    "model = trainModel(model, lang, pairs, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EOS'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang.index2word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, lang, sentences):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(lang, sentences[1])\n",
    "  \n",
    "        decoded_words = []\n",
    "  \n",
    "        output = model(input_tensor, output_tensor)\n",
    "       \n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1)\n",
    "            # print(topi)\n",
    "\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi[0].item()])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(model, lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "#         print('source {}'.format(pair[0]))\n",
    "#         print('target {}'.format(pair[1]))\n",
    "        output_words = evaluate(model, lang, pair)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'garden',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'SOQ',\n",
       "  'Where',\n",
       "  'is',\n",
       "  'John',\n",
       "  '?'],\n",
       " ['bedroom'])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluateRandomly(model, lang, pairs)\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 8],\n",
       "         [ 7],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11],\n",
       "         [ 2],\n",
       "         [12],\n",
       "         [ 1]], device='cuda:0'),\n",
       " tensor([[8],\n",
       "         [1]], device='cuda:0'))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorsFromPair(lang, pairs[0])\n",
    "#lang.word2index['SOQ']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
