{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from functools import reduce \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = os.listdir('./tasks')\n",
    "text_files = [i for i in text_files if '.txt' in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure of all tasks have single word answers\n",
    "for f in text_files:\n",
    "    text1 = pd.read_csv('./tasks/'+f, sep=\"\\n\", header=None)\n",
    "    text1.columns = ['text']\n",
    "    ans = []\n",
    "    for t in text1.text:\n",
    "        if '?' in t:\n",
    "            match = re.search(r'[a-zA-z0-9?\\ ]*\\t([\\w \\ ]+)', t)\n",
    "            if match:\n",
    "                ans.append(match.group(1)) \n",
    "                \n",
    "    ans = [i.split(' ') for i in ans]\n",
    "    for i in ans:\n",
    "        if len(i)>1:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split(r'(\\W+)', sent) if x.strip()]\n",
    "\n",
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        #line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            # reset story when line ID=1 (start of new story)\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            # this line is tab separated Q, A &amp;amp;amp;amp;amp; support fact ID\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            # tokenize the words of question\n",
    "            q = tokenize(q)\n",
    "            # Provide all the sub-stories till this question\n",
    "            substory = [x for x in story if x]\n",
    "            # A story ends and is appended to global story data-set\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            # this line is a sentence of story\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "def get_stories(f):\n",
    "    # read the data file and parse 10k stories\n",
    "    data = parse_stories(f.readlines())\n",
    "    # lambda func to flatten the list of sentences into one list\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    # creating list of tuples for each story\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data]\n",
    "    #data = [((story), q, answer) for story, q, answer in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tasks/task_20.txt') as f:\n",
    "    all_stories = get_stories(f)\n",
    "    \n",
    "train_stories, test_stories = train_test_split(all_stories, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Yann', 'is', 'tired', '.'],\n",
       "  ['Antoine', 'is', 'hungry', '.'],\n",
       "  ['Jason', 'is', 'thirsty', '.'],\n",
       "  ['Jason', 'went', 'to', 'the', 'kitchen', '.'],\n",
       "  ['Jason', 'got', 'the', 'milk', '.'],\n",
       "  ['Sumit', 'is', 'bored', '.'],\n",
       "  ['Antoine', 'went', 'to', 'the', 'kitchen', '.']],\n",
       " ['Why', 'did', 'Antoine', 'go', 'to', 'the', 'kitchen', '?'],\n",
       " 'hungry')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor(sequences):\n",
    "    \"\"\"\n",
    "    :param sequences: list of tensors\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num = len(sequences)\n",
    "    max_len = max([len(s) for s in sequences])\n",
    "    out_dims = (num, max_len)\n",
    "    out_tensor = np.zeros((num, max_len))\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = len(tensor)\n",
    "        out_tensor[i, :length] = tensor\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    # story vector initialization\n",
    "    X = []\n",
    "    # query vector initialization\n",
    "    Xq = []\n",
    "    # answer vector intialization\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        # creating list of story word indices\n",
    "        x = [word_idx[w] for w in story]\n",
    "        # creating list of query word indices\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx))\n",
    "        # creating label 1 for the answer word index\n",
    "        y[word_idx[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (padding_tensor(X),\n",
    "            padding_tensor(Xq), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "    \n",
    "vocab = sorted(vocab)\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "vocab = list(vocab)\n",
    "vocab = ['<pad>'] + vocab\n",
    "word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "idx_word = dict((i, c) for i,c in enumerate(vocab))\n",
    "\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
    "                                                               word_idx,\n",
    "                                                               story_maxlen,\n",
    "                                                               query_maxlen)\n",
    "\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
    "                                                            word_idx,\n",
    "                                                            story_maxlen,\n",
    "                                                            query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_no_attention(nn.Module):\n",
    "    def __init__(self, vocab_size, story_embed_size, query_embed_size, story_hidden_dim, query_hidden_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.story_embed_size = story_embed_size\n",
    "        self.query_embed_size = query_embed_size\n",
    "        self.query_maxlen = query_maxlen\n",
    "        self.story_hidden_dim = story_hidden_dim\n",
    "        self.query_hidden_dim = query_hidden_dim\n",
    "        self.story_embeddings = nn.Embedding(vocab_size, story_embed_size)\n",
    "        self.query_embeddings = nn.Embedding(vocab_size, query_embed_size)\n",
    "        self.story_lstm = nn.LSTM(story_embed_size, story_hidden_dim)\n",
    "        self.query_lstm = nn.LSTM(query_embed_size, query_hidden_dim)\n",
    "        self.hidden2label = nn.Linear(story_hidden_dim*story_maxlen+query_hidden_dim*query_maxlen, vocab_size)\n",
    "        self.story_hidden = self.init_story_hidden(story_maxlen)  \n",
    "        self.query_hidden = self.init_query_hidden(query_maxlen)  \n",
    "        \n",
    "    def forward(self, input_sequence, question):\n",
    "        story_embed = self.story_embeddings(input_sequence)\n",
    "        query_embed = self.query_embeddings(question)\n",
    "        \n",
    "        lstm_story_out, _ = self.story_lstm(story_embed, self.story_hidden)\n",
    "        lstm_query_out, _ = self.query_lstm(query_embed, self.query_hidden)\n",
    "        s = lstm_story_out.view(len(lstm_story_out),-1)\n",
    "        q = lstm_query_out.view(len(lstm_query_out),-1)\n",
    "        \n",
    "        c = torch.cat([s,q], dim=1)\n",
    "        y  = self.hidden2label(c)\n",
    "        log_probs = F.log_softmax(y)\n",
    "        return log_probs\n",
    "    \n",
    "        \n",
    "    def init_story_hidden(self, max_len):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, max_len, self.story_hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, max_len, self.story_hidden_dim)))\n",
    "    \n",
    "    def init_query_hidden(self, max_len):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, max_len, self.query_hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, max_len, self.query_hidden_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9600, 34])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = LSTM_no_attention(len(vocab), 10, 2, 5, 2)\n",
    "x=mem(torch.Tensor(inputs_train).long(), torch.Tensor(queries_train).long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "def train(model, optimizer, epochs, story, query, answers):\n",
    "    pad = word_idx['<pad>']\n",
    "    for epoch in range(epochs):\n",
    "        #scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(story, query)\n",
    "        loss = F.nll_loss(outputs, answers.view(-1), ignore_index=pad, reduction='sum')\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch%5==0:\n",
    "            eval(model)\n",
    "        #print(f\"Epoch {epoch+1}: {loss.item()/story.shape[0]}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    outputs = model(torch.Tensor(inputs_test).long(), torch.Tensor(queries_test).long())\n",
    "    ans = np.argmax(answers_test, axis=1)\n",
    "    predicted_ans = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "    print(f\"test accuracy: {np.mean(predicted_ans == ans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.2575\n",
      "test accuracy: 0.31166666666666665\n",
      "test accuracy: 0.59125\n",
      "test accuracy: 0.68875\n",
      "test accuracy: 0.7545833333333334\n",
      "test accuracy: 0.765\n",
      "test accuracy: 0.78625\n",
      "test accuracy: 0.80875\n",
      "test accuracy: 0.8295833333333333\n",
      "test accuracy: 0.8491666666666666\n",
      "test accuracy: 0.8616666666666667\n",
      "test accuracy: 0.86875\n",
      "test accuracy: 0.87125\n",
      "test accuracy: 0.8866666666666667\n",
      "test accuracy: 0.8920833333333333\n",
      "test accuracy: 0.8979166666666667\n"
     ]
    }
   ],
   "source": [
    "mem = LSTM_no_attention(len(vocab), 20, 2, 5, 2)\n",
    "optimizer = torch.optim.Adam(mem.parameters(), 0.1)\n",
    "train(mem, optimizer, 80, torch.Tensor(inputs_train).long(), torch.Tensor(queries_train).long(), torch.Tensor(np.argmax(answers_train, axis=1)).long())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(answers_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(queries_train).shape\n",
    "len(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
