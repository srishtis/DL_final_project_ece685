{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from functools import reduce \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = os.listdir('./tasks')\n",
    "text_files = [i for i in text_files if '.txt' in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure of all tasks have single word answers\n",
    "for f in text_files:\n",
    "    text1 = pd.read_csv('./tasks/'+f, sep=\"\\n\", header=None)\n",
    "    text1.columns = ['text']\n",
    "    ans = []\n",
    "    for t in text1.text:\n",
    "        if '?' in t:\n",
    "            match = re.search(r'[a-zA-z0-9?\\ ]*\\t([\\w \\ ]+)', t)\n",
    "            if match:\n",
    "                ans.append(match.group(1)) \n",
    "                \n",
    "    ans = [i.split(' ') for i in ans]\n",
    "    for i in ans:\n",
    "        if len(i)>1:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(task):\n",
    "    with open(f'./tasks/task_{task}.txt') as f:\n",
    "        all_stories = get_stories(f, flatten=True)\n",
    "\n",
    "    train_stories, test_stories = train_test_split(all_stories, test_size=0.2)\n",
    "\n",
    "    vocab = set()\n",
    "    for story, q, answer in train_stories + test_stories:\n",
    "        vocab |= set(story + q + [answer])\n",
    "\n",
    "    vocab = sorted(vocab)\n",
    "    vocab_size = len(vocab) + 1\n",
    "    story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "    query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "    vocab = list(vocab)\n",
    "    vocab = ['<pad>'] + vocab\n",
    "    word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "    idx_word = dict((i, c) for i,c in enumerate(vocab))\n",
    "\n",
    "    train = vectorize_stories(train_stories,\n",
    "                               word_idx,\n",
    "                               story_maxlen,\n",
    "                               query_maxlen)\n",
    "\n",
    "    test = vectorize_stories(test_stories,\n",
    "                            word_idx,\n",
    "                            story_maxlen,\n",
    "                            query_maxlen)\n",
    "    \n",
    "    return train, test, vocab, word_idx, query_maxlen, story_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_no_attention(nn.Module):\n",
    "    def __init__(self, vocab_size, story_embed_size, query_embed_size, story_hidden_dim, query_hidden_dim, query_maxlen, story_maxlen, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.story_embed_size = story_embed_size\n",
    "        self.query_embed_size = query_embed_size\n",
    "        self.query_maxlen = query_maxlen\n",
    "        self.story_hidden_dim = story_hidden_dim\n",
    "        self.query_hidden_dim = query_hidden_dim\n",
    "        self.story_embeddings = nn.Embedding(vocab_size, story_embed_size)\n",
    "        self.query_embeddings = nn.Embedding(vocab_size, query_embed_size)\n",
    "        # two lstm modules for story and query\n",
    "        self.story_lstm = nn.LSTM(story_embed_size, story_hidden_dim)\n",
    "        self.query_lstm = nn.LSTM(query_embed_size, query_hidden_dim)\n",
    "        #linear layer to convert to vocab size\n",
    "        self.hidden2label = nn.Linear(story_hidden_dim*story_maxlen+query_hidden_dim*query_maxlen, vocab_size)\n",
    "        #hidden layer initilaization for both the lstms\n",
    "        self.story_hidden = self.init_story_hidden(story_maxlen)  \n",
    "        self.query_hidden = self.init_query_hidden(query_maxlen)  \n",
    "        \n",
    "    def forward(self, input_sequence, question):\n",
    "        story_embed = self.story_embeddings(input_sequence)\n",
    "        query_embed = self.query_embeddings(question)\n",
    "        \n",
    "        lstm_story_out, _ = self.story_lstm(story_embed, self.story_hidden)\n",
    "        lstm_query_out, _ = self.query_lstm(query_embed, self.query_hidden)\n",
    "        s = lstm_story_out.view(len(lstm_story_out),-1)\n",
    "        q = lstm_query_out.view(len(lstm_query_out),-1)\n",
    "        \n",
    "        c = torch.cat([s,q], dim=1)\n",
    "        y  = self.hidden2label(c)\n",
    "        log_probs = F.log_softmax(y)\n",
    "        return log_probs\n",
    "    \n",
    "        \n",
    "    def init_story_hidden(self, max_len):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, max_len, self.story_hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, max_len, self.story_hidden_dim)))\n",
    "    \n",
    "    def init_query_hidden(self, max_len):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, max_len, self.query_hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, max_len, self.query_hidden_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "def train_model(model, optimizer, epochs, story, query, answers, test, word_idx):\n",
    "    test_accuracy = []\n",
    "    pad = word_idx['<pad>']\n",
    "    for epoch in range(epochs):\n",
    "        #scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(story, query)\n",
    "        loss = F.nll_loss(outputs, answers.view(-1), ignore_index=pad, reduction='sum')\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch%5==0:\n",
    "            test_accuracy.append(eval(model, test))\n",
    "    return max(test_accuracy)\n",
    "     \n",
    "def eval(model, test):\n",
    "    outputs = model(torch.Tensor(test[0]).long(), torch.Tensor(test[1]).long())\n",
    "    ans = np.argmax(test[2], axis=1)\n",
    "    predicted_ans = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "    return np.mean(predicted_ans == ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 20: 81.38%\n"
     ]
    }
   ],
   "source": [
    "for task in range(20,21):\n",
    "    train, test, vocab, word_idx, query_maxlen, story_maxlen = prepare_data(task)\n",
    "    inputs_train = torch.Tensor(train[0]).long()\n",
    "    queries_train = torch.Tensor(train[1]).long()\n",
    "    answers_train = torch.Tensor(np.argmax(train[2], axis=1)).long()\n",
    "\n",
    "    mem = LSTM_no_attention(len(vocab), 20, 10, 5, 2, query_maxlen, story_maxlen)\n",
    "    optimizer = torch.optim.Adam(mem.parameters(), 0.1)\n",
    "    test_accuracy = train_model(mem, optimizer, 100, inputs_train, queries_train, answers_train, test, word_idx)\n",
    "    print(f\"Task {task}: {np.round(test_accuracy*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
